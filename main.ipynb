{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, Dropout, Flatten, Dense, MaxPooling2D, Input\n",
    "from keras.layers import GlobalAveragePooling2D, Layer, Reshape, Conv2DTranspose, UpSampling2D\n",
    "from keras.applications import vgg19, xception, inception_v3, resnet50\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.datasets import load_files\n",
    "from keras.preprocessing import image\n",
    "from tensorflow import keras\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from keras.utils import np_utils\n",
    "from PIL import ImageFile\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load the dataset files\n",
    "def dataset_loader(filepath):\n",
    "    dataset = load_files(filepath)\n",
    "    return np.asarray(dataset['filenames']), np_utils.to_categorical(np.asarray(dataset['target']), 133)\n",
    "\n",
    "train_files, train_labels = dataset_loader(\"D:/College/Courses/Spring 21/Neural Networks/final/dog-breed-prediction/dogs/train\")\n",
    "val_files, val_labels = dataset_loader(\"D:/College/Courses/Spring 21/Neural Networks/final/dog-breed-prediction/dogs/valid\")\n",
    "test_files, test_labels = dataset_loader(\"D:/College/Courses/Spring 21/Neural Networks/final/dog-breed-prediction/dogs/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a lookup dictionary of label : dog breed\n",
    "dog_breed_labels = glob(\"dogs/train/*/\")\n",
    "dog_breed_labels = [label[15:-1] for label in dog_breed_labels]\n",
    "dog_breed_labels_lookup = dict(zip(list(range(133)), dog_breed_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect if dog in picture using resnet50\n",
    "ResNet50_dog = resnet50.ResNet50(weights = 'imagenet')\n",
    "def is_dog(model, filepath):\n",
    "    input_image = np.expand_dims(image.img_to_array(image.load_img(filepath, target_size = (224,224))), axis=0)\n",
    "    resnet50_image = resnet50.preprocess_input(input_image)\n",
    "    pred_label = np.argmax(model.predict(resnet50_image))\n",
    "    print(pred_label)\n",
    "    return (pred_label >= 151 and pred_label <= 268)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect if human in picture\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "def is_human(filepath):\n",
    "    gray_image = cv2.cvtColor(cv2.imread(filepath), cv2.COLOR_BGR2GRAY)\n",
    "    return len(face_cascade.detectMultiScale(gray_image)) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "val_data = []\n",
    "test_data = []\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# Load the datasets\n",
    "for filepath in train_files:\n",
    "    train_data.append(image.img_to_array(image.load_img(filepath, target_size = (224,224))))\n",
    "train_data = np.asarray(train_data)\n",
    "\n",
    "for filepath in val_files:\n",
    "    val_data.append(image.img_to_array(image.load_img(filepath, target_size = (224,224)))) \n",
    "val_data = np.asarray(val_data)\n",
    "\n",
    "for filepath in test_files:\n",
    "    test_data.append(image.img_to_array(image.load_img(filepath, target_size = (224,224))))\n",
    "test_data = np.asarray(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment the dataset with rotated, shifted, zoomed images\n",
    "image_gen = image.ImageDataGenerator(rotation_range = 25, width_shift_range = 1.3, height_shift_range = 1.3, zoom_range = 0.2)\n",
    "augmented_iter = image_gen.flow(train_data, train_labels, save_to_dir = \"augmented/\", save_format = \"jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit our CNN model\n",
    "original_model = Sequential([\n",
    "    Input(shape=(224,224,3)),\n",
    "    Conv2D(16, kernel_size = (3,3), strides = (2,2), activation = 'relu'),\n",
    "    MaxPooling2D(pool_size = (2,2)),\n",
    "    Conv2D(32, kernel_size = (3,3), strides = (1,1), activation = 'relu'),\n",
    "    MaxPooling2D(pool_size = (2,2)),\n",
    "    Conv2D(64, kernel_size = (3,3), strides = (1,1), activation = 'relu'),\n",
    "    MaxPooling2D(pool_size = (2,2)),\n",
    "    Conv2D(128, kernel_size = (3,3), activation = 'relu'),\n",
    "    MaxPooling2D(pool_size = (2,2)),\n",
    "    Dropout(0.4),\n",
    "    Flatten(),\n",
    "    Dense(1000, activation = 'relu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(133, activation = 'softmax')\n",
    "])\n",
    "\n",
    "original_model.summary()\n",
    "\n",
    "original_model.compile(loss = 'categorical_crossentropy' , optimizer = 'rmsprop', metrics = ['accuracy'])\n",
    "original_model_hist = original_model.fit(train_data, train_labels, validation_data = (val_data, val_labels), epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation accuracy\n",
    "plt.plot(original_model_hist.history['accuracy'])\n",
    "plt.plot(original_model_hist.history['val_accuracy'])\n",
    "plt.title(\"Training Data Model Accuracy\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.legend([\"train\", 'validation'])\n",
    "plt.ylim([0.0, 0.3])\n",
    "plt.xlim([0, 20])\n",
    "plt.show()\n",
    "# plt.savefig(\"Training.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "original_model.evaluate(test_data, test_labels)\n",
    "pred_labels_original = original_model.predict(test_data)\n",
    "\n",
    "print(\"f1 score:\", f1_score(test_labels, tf.one_hot(tf.math.argmax(pred_labels_original, axis = 1), depth = 133), average = 'weighted'))\n",
    "print(\"precision score:\", precision_score(test_labels, tf.one_hot(tf.math.argmax(pred_labels_original, axis = 1), depth = 133), average = 'weighted'))\n",
    "print(\"recall score:\", recall_score(test_labels, tf.one_hot(tf.math.argmax(pred_labels_original, axis = 1), depth = 133), average = 'weighted'))\n",
    "original_model_CM = confusion_matrix(test_labels.argmax(axis=1), tf.math.argmax(pred_labels_original, axis = 1), labels = list(range(133)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 5 accuracy\n",
    "top_5 = np.argsort(pred_labels_original, axis=1)[:, -5:]\n",
    "test_labels_max = tf.math.argmax(test_labels, axis=1)\n",
    "top_5_accuracy = np.mean(np.array([1 if test_labels_max[k] in top_5[k] else 0 for k in range(len(top_5))]))\n",
    "print(\"Top 5 accuracy:\", top_5_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 5 misclassified pairs\n",
    "negative_preds = []\n",
    "for i in range(133):\n",
    "    for j in range(133):\n",
    "        if not i == j:\n",
    "            negative_preds.append([dog_breed_labels_lookup[i], dog_breed_labels_lookup[j], original_model_CM[i,j]])\n",
    "            \n",
    "negative_preds.sort(key=lambda x: x[2], reverse=True)\n",
    "negative_preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model on augmented data as well\n",
    "original_model_aug_hist = original_model.fit(augmented_iter, validation_data = (val_data, val_labels), epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(original_model_aug_hist.history['accuracy'])\n",
    "plt.plot(original_model_aug_hist.history['val_accuracy'])\n",
    "plt.title(\"Augmented Data Model Accuracy\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.legend([\"train\", 'validation'])\n",
    "plt.ylim([0.0, 0.4])\n",
    "plt.xlim([0, 20])\n",
    "plt.show()\n",
    "# plt.savefig(\"Augmented.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random baseline\n",
    "pred_labels_random = tf.one_hot(np.random.randint(0, 133, len(test_labels)), depth = 133)\n",
    "print(\"f1 score:\", f1_score(test_labels, tf.one_hot(tf.math.argmax(pred_labels_random, axis = 1), depth = 133), average = 'weighted'))\n",
    "print(\"precision score:\", precision_score(test_labels, tf.one_hot(tf.math.argmax(pred_labels_random, axis = 1), depth = 133), average = 'weighted'))\n",
    "print(\"recall score:\", recall_score(test_labels, tf.one_hot(tf.math.argmax(pred_labels_random, axis = 1), depth = 133), average = 'weighted'))\n",
    "print(\"accuracy score:\", accuracy_score(test_labels, tf.one_hot(tf.math.argmax(pred_labels_random, axis = 1), depth = 133)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 5 accuracy for augmented model\n",
    "top_5 = np.random.randint(0, 133, (len(test_labels), 5))\n",
    "test_labels_max = tf.math.argmax(test_labels, axis=1)\n",
    "top_5_accuracy = np.mean(np.array([1 if test_labels_max[k] in top_5[k] else 0 for k in range(len(top_5))]))\n",
    "print(\"Top 5 accuracy:\", top_5_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model fitted on augmented data\n",
    "original_model.evaluate(test_data, test_labels)\n",
    "pred_labels_aug = original_model.predict(test_data)\n",
    "\n",
    "print(\"f1 score:\", f1_score(test_labels, tf.one_hot(tf.math.argmax(pred_labels_aug, axis = 1), depth = 133), average = 'weighted'))\n",
    "print(\"precision score:\", precision_score(test_labels, tf.one_hot(tf.math.argmax(pred_labels_aug, axis = 1), depth = 133), average = 'weighted'))\n",
    "print(\"recall score:\", recall_score(test_labels, tf.one_hot(tf.math.argmax(pred_labels_aug, axis = 1), depth = 133), average = 'weighted'))\n",
    "aug_model_CM = confusion_matrix(test_labels.argmax(axis=1), tf.math.argmax(pred_labels_aug, axis = 1), labels = list(range(133)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 5 accuracy for augmented model\n",
    "top_5 = np.argsort(pred_labels_aug, axis=1)[:, -5:]\n",
    "test_labels_max = tf.math.argmax(test_labels, axis=1)\n",
    "top_5_accuracy = np.mean(np.array([1 if test_labels_max[k] in top_5[k] else 0 for k in range(len(top_5))]))\n",
    "print(\"Top 5 accuracy:\", top_5_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 5 misclassified pairs of breeds\n",
    "negative_preds = []\n",
    "for i in range(133):\n",
    "    for j in range(133):\n",
    "        if not i == j:\n",
    "            negative_preds.append([dog_breed_labels_lookup[i], dog_breed_labels_lookup[j], original_model_CM[i,j]])\n",
    "            \n",
    "negative_preds.sort(key=lambda x: x[2], reverse=True)\n",
    "negative_preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vgg19 model\n",
    "# vgg19_features = vgg19.VGG19(include_top = False, input_shape = (224,224,3))\n",
    "# global1 = GlobalAveragePooling2D()(vgg19_features.output)\n",
    "# dropout1 = Dropout(0.3)(global1)\n",
    "# output1 = Dense(133, activation = 'softmax')(dropout1)\n",
    "# vgg19_model = Model(inputs = vgg19_features.inputs, outputs = output1)\n",
    "# vgg19_model.compile(loss = 'categorical_crossentropy' , optimizer = 'rmsprop', metrics = ['accuracy'])\n",
    "# vgg19_model_hist = vgg19_model.fit(train_data, train_labels, validation_data = (val_data, val_labels), epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xception model\n",
    "# xception_features = xception.Xception(include_top = False, input_shape = (224,224,3))\n",
    "# global2 = GlobalAveragePooling2D()(xception_features.output)\n",
    "# dropout2 = Dropout(0.3)(global2)\n",
    "# output2 = Dense(133, activation = 'softmax')(dropout2)\n",
    "# xception_model = Model(inputs = xception_features.inputs, outputs = output2)\n",
    "# xception_model.compile(loss = 'categorical_crossentropy' , optimizer = 'rmsprop', metrics = ['accuracy'])\n",
    "# xception_model_hist = xception_model.fit(train_data, train_labels, validation_data = (val_data, val_labels), epochs = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that takes in a test image, and returns corresponding model output\n",
    "def classify_image(img_path):\n",
    "    image_input = np.expand_dims(image.img_to_array(image.load_img(img_path, target_size = (224,224))), axis=0)\n",
    "    if is_dog(ResNet50_dog, img_path):\n",
    "        print(\"The breed is:\", dog_breed_labels_lookup[original_model.predict(image_input).argmax(axis=1)[0]])\n",
    "    elif is_human(img_path):\n",
    "        print(\"The human looks like:\", dog_breed_labels_lookup[original_model.predict(image_input).argmax(axis=1)[0]])\n",
    "    else:\n",
    "        print(\"Error, neither human nor dog found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add training data with lower image dimensions\n",
    "train_data_vae = []\n",
    "\n",
    "for filepath in train_files:\n",
    "    train_data_vae.append(image.img_to_array(image.load_img(filepath, target_size = (64,64))))\n",
    "\n",
    "# Normalize the values \n",
    "train_data_vae = np.asarray(train_data_vae).astype('float32') / 255\n",
    "\n",
    "# Add testing data in same fashion\n",
    "test_data_vae = []\n",
    "\n",
    "for filepath in test_files:\n",
    "    test_data_vae.append(image.img_to_array(image.load_img(filepath, target_size = (64,64))))\n",
    "    \n",
    "test_data_vae = np.asarray(test_data_vae).astype('float32') / 255\n",
    "    \n",
    "# Encoder architecture\n",
    "input_img = Input(shape=(64, 64, 3))  \n",
    "x = Conv2D(48, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(96, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(192, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "encoded_layer = Conv2D(32, (1, 1), activation='relu', padding='same')(x)\n",
    "\n",
    "# latent space dimensions\n",
    "latent_dim = (8,8,32)\n",
    "\n",
    "# Decoder architecture\n",
    "latent_input = Input(shape = latent_dim)\n",
    "x = Conv2D(192, (1, 1), activation='relu', padding='same')(latent_input)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(192, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(96, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(48, (3, 3), activation='relu', padding='same')(x)\n",
    "decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "# COMPILE\n",
    "encoder = Model(input_img, encoded_layer)\n",
    "decoder = Model(latent_input, decoded)\n",
    "autoencoder = Model(input_img, decoder(encoded))\n",
    "\n",
    "autoencoder.compile(optimizer='Adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit autoencoder on training data\n",
    "autoencoder.fit(train_data_vae, train_data_vae, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get decoded images \n",
    "decoded_imgs = decoder.predict(encoder.predict(test_data_vae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot original and reconstructed images\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(10):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, 10, i + 1)\n",
    "    plt.imshow(test_data_vae[i])\n",
    "    plt.title(\"original\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, 10, i + 1 + 10)\n",
    "    plt.imshow(decoded_imgs[i])\n",
    "    plt.title(\"reconstructed\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode images to latent space\n",
    "encoded_imgs = encoder.predict(test_data_vae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to walk around from one image in latent space to another\n",
    "encoded_imgs_2 = encoded_imgs[:10]\n",
    "delta = 0.4\n",
    "for i in range(10):\n",
    "    encoded_imgs_2[i] += delta\n",
    "\n",
    "decoded_imgs_2 = decoder.predict(encoded_imgs_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot new images\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(10):\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, 10, i + 1 + 10)\n",
    "    plt.imshow(decoded_imgs_2[i])\n",
    "    plt.title(\"reconstructed\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
